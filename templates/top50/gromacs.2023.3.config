[SERVER]
11.11.11.11
 
[DOWNLOAD]
gromacs/2023.3 http://ftp.gromacs.org/pub/gromacs/gromacs-2023.3.tar.gz
Testcase https://repository.prace-ri.eu/ueabs/GROMACS/2.2/GROMACS_TestCaseC.tar.xz
 
[DEPENDENCY]
set -e
set -x
module purge
module use $JARVIS_MODULES/modules
./jarvis -install cmake/3.28.2 any
./jarvis -install hpckit/2025.3.30 any
module load hpckit/2025.3.30
module load bisheng/compiler4.2.0/bishengmodule
./jarvis -install openblas/0.3.14 any
module load bisheng/hmpi25.0.0/hmpi
export CC=mpicc CXX=mpicxx FC=mpifort
./jarvis -install fftw/3.3.10 clang+mpi
#解压源码
cd $JARVIS_DEV
tar -xvf ${JARVIS_DOWNLOAD}/gromacs-2023.3.tar.gz
#解压算例
CASE_DIR=${JARVIS_JOBSCRIPT}/gromacs/2023.3
if [ ! -d $CASE_DIR ]; then
    mkdir -p $CASE_DIR
    cd $CASE_DIR
    tar -xf ${JARVIS_DOWNLOAD}/GROMACS_TestCaseC.tar.xz
fi

[ENV]
module purge
module use $JARVIS_MODULES/modules
module load cmake/3.28.2
module load hpckit/2025.3.30
#低版本GCC会报错
module add gcc/compiler12.3.1/gccmodule
module load bisheng/compiler4.2.0/bishengmodule
module load bisheng/hmpi25.0.0/hmpi
module load openblas/0.3.14
module load fftw/3.3.10-bisheng4.2.0-hmpi25.0.0
compile_dir=$(dirname $(dirname $(which clang)))
export gcc_compile_dir=$(dirname $(dirname $(which gcc)))
export gromacs_dir=$JARVIS_DEV/gromacs-2023.3

[APP]
app_name = gromacs
app_version = 2023.3
compiler = bisheng+mpi
build_dir = $JARVIS_DEV/gromacs-2023.3
binary_dir = $JARVIS_DEV/gromacs-2023.3/build/bin
case_dir = ${JARVIS_JOBSCRIPT}/gromacs/2023.3/GROMACS_TestCaseC
 
[BUILD]
cmake --version
mkdir -p build
cd build
FLAGS="-mcpu=linxicore9100 -O3 -ffast-math -mllvm --aarch64-sched-inline-asm=false -mllvm -unroll-threshold-aggressive=600"
LD_FLAGS="-mcpu=linxicore9100 -O3 -L${gcc_compile_dir}/lib64 -lgfortran -lbsmath -lflang -L${compile_dir}/lib/jemalloc-64kbpage -ljemalloc"
 
CFLAGS=$FLAGS CXXFLAGS=$FLAGS LDFLAGS=$LD_FLAGS CC=mpicc CXX=mpicxx FC=mpifort cmake -DCMAKE_INSTALL_PREFIX=$1 -DBUILD_SHARED_LIBS=on -DBUILD_TESTING=on -DREGRESSIONTEST_DOWNLOAD=off -DGMX_BUILD_OWN_FFTW=off -DGMX_SIMD=ARM_SVE -DGMX_SIMD_ARM_SVE_LENGTH=256 -DGMX_DOUBLE=off -DGMX_EXTERNAL_BLAS=on -DGMX_EXTERNAL_LAPACK=on -DGMX_FFT_LIBRARY=fftw3 -DGMX_BLAS_USER=${OPENBLAS_PATH}/lib/libopenblas.a -DGMX_LAPACK_USER=${OPENBLAS_PATH}/lib/libopenblas.a -DFFTWF_LIBRARY=$FFTW_PATH/lib/libfftw3f.so -DFFTWF_INCLUDE_DIR=$FFTW_PATH/include -DGMX_X11=off -DGMX_OPENMP=off -DGMX_MPI=on -DGMX_THREAD_MPI=off -DGMX_CYCLE_SUBCOUNTERS=off ../
 
make -j40 V=1
make install
 
[CLEAN]
rm -rf build
 
[RUN]
run = mpirun -np 574 --allow-run-as-root -x UCX_TLS=sm --bind-to cpulist:ordered -mca pml ucx -mca btl ^vader,tcp,openib,uct
binary = gmx_mpi mdrun -dlb yes -v -nsteps 4000 -noconfout -pin on -pinoffset 0 -ntomp 1 -npme 112 -g md_sve_0229-ucpg-bisheng-2P.log -s stmv.28M.tpr
nodes = 1

[JOB]
#!/bin/bash
#DSUB -n gmx
#DSUB --job_type cosched
#DSUB -N 1
#DSUB -R "cpu=128"
#DSUB -o gmx_%J.log
#DSUB -e gmx_err_%J.log
#DSUB -T '2h'

export HOSTFILE=hostfile.gmx
rm -f $HOSTFILE
touch $HOSTFILE
cat ${CCSCHEDULER_ALLOC_FILE} | sort > $HOSTFILE
mpirun -np 128 --hostfile $HOSTFILE -x UCX_TLS=sm --bind-to cpulist:ordered -mca pml ucx -mca btl ^vader,tcp,openib,uct ${gromacs_dir}/build/bin/gmx_mpi mdrun -dlb yes -v -nsteps 4000 -noconfout -pin on -pinoffset 0 -ntomp 1 -npme 8 -g 3-5-pme8-128C.log -s stmv.28M.tpr
